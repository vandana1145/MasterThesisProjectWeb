{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5cf534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # will be needed for saving preprocessing details\n",
    "import numpy as np # for data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "from sklearn.model_selection import train_test_split # will be used for data split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder # for preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier # for training the algorithm\n",
    "from sklearn.ensemble import ExtraTreesClassifier # for training the algorithm\n",
    "import joblib # for saving algorithm and preprocessing objects\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "210cb3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('Data.csv')\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f89fc3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking care of the missing data\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean', verbose = 0)\n",
    "imputer = imputer.fit(X[:, 1:]) #upper bound is not included, but lower bound\n",
    "X[:, 1:8] = imputer.transform(X[:, 1:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale data (between 0 and 1)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4612c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b19d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the dependent variable\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y = labelencoder_Y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/vandana/.local/lib/python3.8/site-packages/imblearn/utils/_validation.py:587: FutureWarning: Pass sampling_strategy=minority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Implementing SMOTE for the Imbalanced data in Multi-class classification\n",
    "smote=SMOTE(\"minority\")\n",
    "X,y=smote.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/vandana/.local/lib/python3.8/site-packages/imblearn/utils/_validation.py:587: FutureWarning: Pass sampling_strategy=minority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# To balance another minority class\n",
    "smote=SMOTE(\"minority\")\n",
    "X,y=smote.fit_resample(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['1'] = RandomForestClassifier(max_features=1)\n",
    "    models['2'] = RandomForestClassifier(max_features=2)\n",
    "    models['3'] = RandomForestClassifier(max_features=3)\n",
    "    models['4'] = RandomForestClassifier(max_features=4)\n",
    "    models['5'] = RandomForestClassifier(max_features=5)\n",
    "    models['6'] = RandomForestClassifier(max_features=6)\n",
    "    models['7'] = RandomForestClassifier(max_features=7)\n",
    "    models['8'] = RandomForestClassifier(max_features=8)\n",
    "    return models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a give model using cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def evaluate_model(model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 0.474 (0.121)\n",
      "2 0.510 (0.114)\n",
      "3 0.490 (0.118)\n",
      "4 0.488 (0.117)\n",
      "5 0.523 (0.126)\n",
      "6 0.502 (0.121)\n",
      "7 0.486 (0.120)\n",
      "8 0.488 (0.142)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=8)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3409090909090909\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Predictions\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle Model\n",
    "pd.to_pickle(model, r'.new_randomforest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle the model\n",
    "model = pd.read_pickle(r'.new_randomforest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take inputs from the user\n",
    "Floor_Num = float(input(\"Enter Number of Floors: \"))\n",
    "Total_Floor_Area = float(input(\"Enter Total Floor Area: \"))\n",
    "Column_Area = float(input(\"Enter Column Area: \"))\n",
    "Concrete_Wall_AreaNS = float(input(\"Enter Concrete Wall AreaNS: \"))\n",
    "Concrete_Wall_AreaEW = float(input(\"Enter Concrete_Wall_AreaEW: \"))\n",
    "Masonry_Wall_AreaNS = float(input(\"Enter Masonry_Wall_AreaNS: \"))\n",
    "Masonry_Wall_AreaEW = float(input(\"Enter Masonry_Wall_AreaEW: \"))\n",
    "Captive_Columns = bool(input(\"Enter Captive_Columns: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "results = model.predict([[Floor_Num, Total_Floor_Area, Column_Area, Concrete_Wall_AreaNS, Concrete_Wall_AreaEW, Masonry_Wall_AreaNS, Masonry_Wall_AreaEW, Captive_Columns]])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd01949c0c6eb6f836478006a9f6300681a60cd2c2e9487a6098efe3997da41e417",
   "display_name": "Python 3.8.5 64-bit ('anaconda3': virtualenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "1949c0c6eb6f836478006a9f6300681a60cd2c2e9487a6098efe3997da41e417"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}